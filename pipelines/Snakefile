from snakemake.utils import Paramspace
import pandas as pd
import json

# declare a dataframe to be a paramspace
paramspace = Paramspace(pd.read_csv("../tests/mocks/snakemake_params.tsv", sep="\t"))

rule all:
    input:
        # Aggregate over entire parameter space (or a subset thereof if needed)
        # of course, something like this can happen anywhere in the workflow (not
        # only at the end).
        expand("results/simulations/{params}.tsv", params=paramspace.instance_patterns)

rule generate_data:
    params:
        # automatically translate the wildcard values into an instance of the param space
        # in the form of a dict (here: {"alpha": ..., "beta": ..., "gamma": ...})
        simulation = paramspace.instance,

    output:
        f"results/simulations/{paramspace.wildcard_pattern}.tsv"
    shell:
        'simulate_data --config "{params.simulation}" --output {output}'


# rule generate_data:
#     input:
#         "/Users/skanduri/Documents/old_mac/PycharmProjects/fdr_hacking/tests/mocks/test_config_file.yaml"
#     output:
#         "/Users/skanduri/Documents/Projects/fdr_hacking/experiments/dataset_{num_datasets}.tsv"
#     shell:
#         "simulate_data --config {input} --output {output}"

#
# rule statistical_analysis:
#     input:
#         config = "/Users/skanduri/Documents/old_mac/PycharmProjects/fdr_hacking/tests/mocks/test_config_file.yaml",
#         data = "/Users/skanduri/Documents/Projects/fdr_hacking/experiments/dataset_{num_datasets}.tsv"
#     output:
#         "/Users/skanduri/Documents/Projects/fdr_hacking/experiments/results_{num_datasets}.tsv"
#     shell:
#         "statistical_test --config {input.config} --dataset {input.data} --output {output}"
